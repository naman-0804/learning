{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d72f600",
   "metadata": {},
   "source": [
    "Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ab60be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # Import the pandas library for data manipulation\n",
    "\n",
    "data={  # Define a dictionary with sample data\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
    "    'Age': [24,None, 22, None],\n",
    "    'City': ['New York', 'Los Angeles', None, 'Chicago'],\n",
    "    'Salary': [70000, 80000, None, 60000]\n",
    "}\n",
    "\n",
    "df=pd.DataFrame(data)                   # Create a DataFrame from the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3de24e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name   Age         City   Salary\n",
      "0    Alice  24.0     New York  70000.0\n",
      "1      Bob   NaN  Los Angeles  80000.0\n",
      "2  Charlie  22.0         None      NaN\n",
      "3    David   NaN      Chicago  60000.0\n",
      "Name      0\n",
      "Age       2\n",
      "City      1\n",
      "Salary    1\n",
      "dtype: int64\n",
      "    Name   Age      City   Salary\n",
      "0  Alice  24.0  New York  70000.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df)  # Print the DataFrame\n",
    "print(df.isnull().sum())              # Print the count of missing values in each column\n",
    "print(df.dropna())                    # Print the DataFrame after dropping rows with missing values\n",
    "print(\"\")\n",
    "                           # Print the DataFrame after filling miSsing values in 'Age' with the mean age\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca4393b",
   "metadata": {},
   "source": [
    "Missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4a33164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name   Age         City   Salary\n",
      "0    Alice  24.0     New York  70000.0\n",
      "1      Bob  23.0  Los Angeles  80000.0\n",
      "2  Charlie  22.0         None  70000.0\n",
      "3    David  23.0      Chicago  60000.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##Handling missing values by filling them with the mean of the column\n",
    "\n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean()) # Fill missing values in 'Age' with the mean age\n",
    "df['Salary']=df['Salary'].fillna(df['Salary'].mean()) # Fill missing values in 'Salary' with the mean salary\n",
    "print(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e50d47",
   "metadata": {},
   "source": [
    "Data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1408f154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f07769cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Name  Gender     City Passed  encoded-Passed\n",
      "0     Alice  Female  Chicago    Yes               1\n",
      "1       Bob    Male  Chicago     No               0\n",
      "2   Charlie    Male  Chicago    Yes               1\n",
      "3     David    Male  Houston     No               0\n",
      "4       Eve  Female  Houston    Yes               1\n",
      "5     Frank    Male  Houston     No               0\n",
      "6     Grace  Female  Houston    Yes               1\n",
      "7    Hannah  Female   Dallas     No               0\n",
      "8       Ian    Male   Dallas    Yes               1\n",
      "9     Julia  Female   Austin     No               0\n",
      "10    Kevin    Male   Austin    Yes               1\n",
      "11    Laura  Female   Austin     No               0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Encoding categorical values using label encoding ,one-hot encoding\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df['encoded-Passed']=le.fit_transform(df['Passed']) # Label encoding for 'Passed' column\n",
    "print(df)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f44804f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One hot encoding for 'City' column\n",
      "       Name  Gender Passed  encoded-Passed  City_Austin  City_Chicago  \\\n",
      "0     Alice  Female    Yes               1            0             1   \n",
      "1       Bob    Male     No               0            0             1   \n",
      "2   Charlie    Male    Yes               1            0             1   \n",
      "3     David    Male     No               0            0             0   \n",
      "4       Eve  Female    Yes               1            0             0   \n",
      "5     Frank    Male     No               0            0             0   \n",
      "6     Grace  Female    Yes               1            0             0   \n",
      "7    Hannah  Female     No               0            0             0   \n",
      "8       Ian    Male    Yes               1            0             0   \n",
      "9     Julia  Female     No               0            1             0   \n",
      "10    Kevin    Male    Yes               1            1             0   \n",
      "11    Laura  Female     No               0            1             0   \n",
      "\n",
      "    City_Dallas  City_Houston  \n",
      "0             0             0  \n",
      "1             0             0  \n",
      "2             0             0  \n",
      "3             0             1  \n",
      "4             0             1  \n",
      "5             0             1  \n",
      "6             0             1  \n",
      "7             1             0  \n",
      "8             1             0  \n",
      "9             0             0  \n",
      "10            0             0  \n",
      "11            0             0  \n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding for 'City' column\n",
    "print(\"One hot encoding for 'City' column\")\n",
    "one_hot_encoded_df = pd.get_dummies(df, columns=['City'], prefix='City')\n",
    "bool_cols = one_hot_encoded_df.select_dtypes(include='bool').columns #take booleean columns\n",
    "one_hot_encoded_df[bool_cols] = one_hot_encoded_df[bool_cols].astype(int) ##now convert boolean columns to int\n",
    "print(one_hot_encoded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91d4342",
   "metadata": {},
   "source": [
    "Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "07f9cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=pd.read_csv('scaling.csv');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ce0142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature1_scaled  feature2_scaled\n",
      "0        -0.620919        -1.666344\n",
      "1         0.162483         0.341299\n",
      "2        -1.404321        -0.863287\n",
      "3         1.584213         1.545886\n",
      "4        -0.969098        -0.461758\n",
      "5         0.858841         0.742828\n",
      "6        -0.359785        -1.264815\n",
      "7         1.265049         1.144357\n",
      "8        -1.143187        -0.060229\n",
      "9         0.626722         0.542064\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scaler=StandardScaler()  # Initialize the StandardScaler\n",
    "X_scaled=scaler.fit_transform(df[['feature1','feature2']])  # Fit and transform the features \n",
    "df_standard_scaled = pd.DataFrame(X_scaled, columns=['feature1_scaled', 'feature2_scaled'])\n",
    "print(df_standard_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e28bc6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature1_scaled  feature2_scaled\n",
      "0         0.262136           0.0000\n",
      "1         0.524272           0.6250\n",
      "2         0.000000           0.2500\n",
      "3         1.000000           1.0000\n",
      "4         0.145631           0.3750\n",
      "5         0.757282           0.7500\n",
      "6         0.349515           0.1250\n",
      "7         0.893204           0.8750\n",
      "8         0.087379           0.5000\n",
      "9         0.679612           0.6875\n"
     ]
    }
   ],
   "source": [
    "scaler=MinMaxScaler()  # Initialize the MinMaxScaler\n",
    "X_scaled=scaler.fit_transform(df[['feature1','feature2']])  # Fit and transform the features\n",
    "df_minmax_scaled = pd.DataFrame(X_scaled, columns=['feature1_scaled', 'feature2_scaled'])\n",
    "print(df_minmax_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318732cf",
   "metadata": {},
   "source": [
    "Spliting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02673da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Training data\n",
      "   study_hours\n",
      "5            7\n",
      "0            2\n",
      "7            9\n",
      "2            4\n",
      "9           11\n",
      "4            6\n",
      "3            5\n",
      "6            8\n",
      "Feature Testing data\n",
      "   study_hours\n",
      "8           10\n",
      "1            3\n",
      "Target Training data\n",
      "   Test_score\n",
      "5          75\n",
      "0          50\n",
      "7          85\n",
      "2          60\n",
      "9          95\n",
      "4          70\n",
      "3          65\n",
      "6          80\n",
      "Target Testing data\n",
      "   Test_score\n",
      "8          90\n",
      "1          55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "data={\n",
    "    'study_hours':[2,3,4,5,6,7,8,9,10,11],\n",
    "    'Test_score':[50,55,60,65,70,75,80,85,90,95]\n",
    "}\n",
    "df=pd.DataFrame(data)\n",
    "Standard_Scaler=StandardScaler()\n",
    "Scaled=Standard_Scaler.fit_transform(df)\n",
    "#print(pd.DataFrame(Scaled,columns=['study_hours','Test_score']))\n",
    "X=df[['study_hours']]  # Features\n",
    "y=df[['Test_score']]     # Target variable\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42) # Split the data into training and testing sets\n",
    "print(\"Feature Training data\")\n",
    "print(X_train)\n",
    "print(\"Feature Testing data\")\n",
    "print(X_test)\n",
    "print(\"Target Training data\")\n",
    "print(y_train)\n",
    "print(\"Target Testing data\")\n",
    "print(y_test)\n",
    "# Now, X_train and y_train can be used to train a machine learning model, and X_test and y_test can be used to evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1b7e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values\n",
      "[[90.]\n",
      " [55.]]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
